{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "139c1e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ester/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Bibliotecas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import euclidean\n",
    "import string\n",
    "import spacy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45a0d20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>Word_count</th>\n",
       "      <th>Message_clean</th>\n",
       "      <th>Word_count_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>20</td>\n",
       "      <td>crazy available bugis great world buffet cine ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>6</td>\n",
       "      <td>lar joke wif oni</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>28</td>\n",
       "      <td>free entry wkly comp win cup final tkts text r...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>11</td>\n",
       "      <td>early hor</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>13</td>\n",
       "      <td>nah think go usf life</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>30</td>\n",
       "      <td>time try contact pound prize claim easy minute...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>8</td>\n",
       "      <td>go esplanade home</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>10</td>\n",
       "      <td>pity mood soany suggestion</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>26</td>\n",
       "      <td>guy bitching act like interested buy week give...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>6</td>\n",
       "      <td>rofl true</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                            Message  Word_count  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...          20   \n",
       "1      ham                      Ok lar... Joking wif u oni...           6   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...          28   \n",
       "3      ham  U dun say so early hor... U c already then say...          11   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...          13   \n",
       "...    ...                                                ...         ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...          30   \n",
       "5568   ham               Will ü b going to esplanade fr home?           8   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...          10   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...          26   \n",
       "5571   ham                         Rofl. Its true to its name           6   \n",
       "\n",
       "                                          Message_clean  Word_count_clean  \n",
       "0     crazy available bugis great world buffet cine ...                10  \n",
       "1                                      lar joke wif oni                 4  \n",
       "2     free entry wkly comp win cup final tkts text r...                15  \n",
       "3                                             early hor                 2  \n",
       "4                                 nah think go usf life                 5  \n",
       "...                                                 ...               ...  \n",
       "5567  time try contact pound prize claim easy minute...                 9  \n",
       "5568                                  go esplanade home                 3  \n",
       "5569                         pity mood soany suggestion                 4  \n",
       "5570  guy bitching act like interested buy week give...                 9  \n",
       "5571                                          rofl true                 2  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_clean = pd.read_csv(\"df_ex1_clean.csv\")\n",
    "display(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e135d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['Message_clean'] = df_clean['Message_clean'].fillna('').astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935356da",
   "metadata": {},
   "source": [
    "### Passo 8: Modelos Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88c5ca5",
   "metadata": {},
   "source": [
    "BERT Zero-shot - Extração de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados\n",
    "texts = df_clean['Message_clean'].tolist()\n",
    "labels_texto = df_clean['Label'].tolist()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8320df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tenta usar a gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval() # Coloca o modelo em modo de avaliação, não de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcf2d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Essa classe cuida da tokenização do texto, tratamento do comprimento da sequência e fornece um pacote\n",
    "# organizado com IDs de entrada, máscaras de atêncção e rótulos para o modelo aprender \n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}\n",
    "\n",
    "# Cria uma instância do dataset\n",
    "meu_dataset = TextClassificationDataset(texts, labels, tokenizer, max_length=128)\n",
    "\n",
    "# Entrega o dataset para o DataLoader\n",
    "meu_dataloader = DataLoader(meu_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71545297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a extração de features do BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraindo vetores BERT: 100%|██████████| 349/349 [01:27<00:00,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extração concluída!\n",
      "Formato da matriz de features (X): (5572, 768)\n",
      "Formato do vetor de rótulos (y): (5572,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando a extração de features do BERT\")\n",
    "\n",
    "# Listas para guardar os resultados de cada lote\n",
    "lista_de_vetores = []\n",
    "lista_de_rotulos = []\n",
    "\n",
    "# Loop de extração (sem treinamento, pois é o zero shot)\n",
    "# torch.no_grad() desativa o cálculo de gradientes, o que economiza\n",
    "# memória e acelera o processo\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(meu_dataloader, desc=\"Extraindo vetores BERT\"):\n",
    "        \n",
    "        # Mover os dados do lote para a GPU\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label']\n",
    "\n",
    "        # Passar os dados pelo modelo BERT\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # A saída que quero é a 'last_hidden_state'.\n",
    "        # Ela contém os vetores de saída para todos os tokens de todas as frases do lote.\n",
    "        # O formato é: [tamanho_do_lote, tamanho_da_sequencia, tamanho_do_vetor]\n",
    "        # Queremos o vetor do token [CLS], que é sempre o primeiro (índice 0).\n",
    "        vetores_cls = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Adicionar os resultados do lote às nossas listas.\n",
    "        # É importante mover os tensores de volta para a CPU com .cpu()\n",
    "        lista_de_vetores.append(vetores_cls.cpu())\n",
    "        lista_de_rotulos.append(labels)\n",
    "\n",
    "# Juntar os resultados de todos os lotes em tensores únicos\n",
    "X_bert = torch.cat(lista_de_vetores, dim=0)\n",
    "y_bert = torch.cat(lista_de_rotulos, dim=0)\n",
    "\n",
    "# Converter para o formato NumPy, que é o que o scikit-learn usa\n",
    "X_bert_numpy = X_bert.numpy() # Matriz onde cada linha é o vetor de 768 dimensões que representa uma das mensagens\n",
    "y_bert_numpy = y_bert.numpy() # Um vetor com os rótulos numéricos correspondentes\n",
    "\n",
    "print(\"\\nExtração concluída!\")\n",
    "print(\"Formato da matriz de features (X):\", X_bert_numpy.shape)\n",
    "print(\"Formato do vetor de rótulos (y):\", y_bert_numpy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1178d85",
   "metadata": {},
   "source": [
    "## Utilizando a representação gerada pelo BERT nos classificadores novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f22c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Árvore de decisão\n",
    "\n",
    "def arvore_de_decisao(X_train, y_train, X_test, y_test):\n",
    "    parametros = {\n",
    "        'criterion': ['gini', 'entropy'], # Função usada para medir a qualidade de uma divisão\n",
    "        'max_depth': [None, 10, 20], # Profundidade máxima \n",
    "        'min_samples_split': [2, 5, 10], # Mínimo de amostras exigido para dividir um nó\n",
    "        'min_samples_leaf': [1, 2, 4] # Mínimo de amostras exigido em um nó folha\n",
    "    }\n",
    "\n",
    "    # Treinando a árvore de decisão\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=clf, param_grid=parametros, cv=5, scoring='accuracy')\n",
    "    #cv =5 significa que os dados sao divididos em 5 partes. O modelo é treinado 5 vezes, utilizando 4 partes\n",
    "    # para treino.\n",
    "\n",
    "    grid_search.fit(X_train, y_train) # Treina o modelo utilizando os melhores parametros encontrados\n",
    "\n",
    "    print(\"Melhores parâmetros: \", grid_search.best_params_)\n",
    "\n",
    "    melhor_clf = grid_search.best_estimator_ # treina novamente com os melhores parametros\n",
    "    y_pred = melhor_clf.predict(X_test) # Fazendo a previsão no conjunto de teste\n",
    "\n",
    "    acuracia = accuracy_score(y_test, y_pred)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(f\"\\nAcurácia com os melhores parâmetros: {acuracia}\")\n",
    "    print(f\"F1 Score (macro) com os melhores parâmetros: {f1_macro}\")\n",
    "\n",
    "    #plt.figure(figsize=(20,10))\n",
    "    #tree.plot_tree(melhor_clf, max_depth=2, feature_names=vectorizer.get_feature_names_out(), class_names=codificador.classes_, filled=True)\n",
    "    #plt.show()\n",
    "    # max_depth profundidade da árvore\n",
    "    # filled=True colore os nós de acordo com a classe predominante\n",
    "    # feature_names mostra quais palavras sao mais importantes para as decisoes\n",
    "\n",
    "    return grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e9e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN - K-Nearest Neighbor\n",
    "\n",
    "def knn(X_train, y_train, X_test, y_test):\n",
    "    parametros = {'n_neighbors': [1, 3, 5, 7, 9],\n",
    "                'weights': ['uniform', 'distance'],\n",
    "                'metric': ['euclidean', 'manhattan']}\n",
    "\n",
    "    # Aplicando KNN\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=knn, param_grid=parametros, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train) # Treina o modelo com diferentes combinações\n",
    "    print(\"Melhores parâmetros: \", grid_search.best_params_)\n",
    "\n",
    "    melhor_knn = grid_search.best_estimator_\n",
    "    melhor_y_pred = melhor_knn.predict(X_test) # Realiza predições com o modelo ajustado\n",
    "\n",
    "    acuracia = accuracy_score(y_test, melhor_y_pred)\n",
    "    f1_macro = f1_score(y_test, melhor_y_pred, average='macro')\n",
    "\n",
    "    print(f\"Acurácia com os melhores parâmetros: {acuracia}\")\n",
    "    print(f\"F1 Score (macro) com os melhores parâmetros: {f1_macro}\")\n",
    "\n",
    "    return grid_search.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c51cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM \n",
    "\n",
    "def svm_modelo(X_train, y_train, X_test, y_test):\n",
    "    parametros = {\n",
    "        'C': [1, 10],  # Parâmetro C\n",
    "        'gamma': [0.1, 'auto', 'scale'],  # Parâmetro gamma\n",
    "        'kernel': ['rbf', 'linear']  # Tipos de kernel\n",
    "    }\n",
    "    # Parâmetro C pequeno tolera mais erros (evita overfitting) - está com valor padrão\n",
    "    # Parâmetro gamma pequeno define que cada ponto de treino tem influencia ampla resultando em \n",
    "    # uma fronteira maior - está com valor padrão\n",
    "\n",
    "    svc = svm.SVC()\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=svc, param_grid=parametros, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Melhores parâmetros encontrados: {grid_search.best_params_}\")\n",
    "\n",
    "    # Fazendo a previsão com os melhores parametros\n",
    "    melhor_svm = grid_search.best_estimator_\n",
    "    y_pred = melhor_svm.predict(X_test)\n",
    "\n",
    "    print(f\"Acurácia: {accuracy_score(y_test, y_pred)}\")\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"F1-Score Macro: {f1_macro}\")\n",
    "\n",
    "    return grid_search.best_params_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6a78dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_intervalo_confianca(valores):\n",
    "    media = np.mean(valores)\n",
    "    desvio_padrao = np.std(valores)\n",
    "    n = len(valores)\n",
    "\n",
    "    t_critico = stats.t.ppf(0.975, df=n-1) # t Student (95% de confiança)\n",
    "\n",
    "    erro_padrao = desvio_padrao/np.sqrt(n)\n",
    "\n",
    "    intervalo_confianca = t_critico * erro_padrao\n",
    "\n",
    "    return media, desvio_padrao, intervalo_confianca\n",
    "\n",
    "def comparar_modelos_teste_t(resultados):\n",
    "    # Converte as chaves do dicionário 'resultados' em uma lista de modelos\n",
    "    modelos = list(resultados.keys())\n",
    "    acuracias = [resultados[modelo] for modelo in modelos]\n",
    "\n",
    "    comparacoes = []\n",
    "    valores_p = []\n",
    "\n",
    "    # Comparar todos os pares de modelos com o teste t\n",
    "    for i in range(len(modelos)):\n",
    "        for j in range(i+1, len(modelos)):\n",
    "            # Realiza o Teste T entre os dois modelos e extrai o valor p\n",
    "            _, valor_p = stats.ttest_ind(acuracias[i], acuracias[j])\n",
    "            comparacoes.append(((modelos[i], modelos[j]), valor_p))\n",
    "            print(f\"Teste T entre {modelos[i]} e {modelos[j]}: valor_p = {valor_p:.4f}\")\n",
    "\n",
    "    # Correção de Bonferroni: ajusta o valor p para múltiplas comparações\n",
    "    bonferroni_valores_p = [p * len(comparacoes) for p in comparacoes]\n",
    "\n",
    "    # Loop para exibir os valores p corrigidos pelo método de Bonferroni\n",
    "    for idx, ((modelo1, modelo2), valor_p) in enumerate(comparacoes):\n",
    "        p_corrigido = valor_p * len(comparacoes)\n",
    "        print(f\"P-value corrigido Bonferroni ({modelo1} vs {modelo2}): {p_corrigido:.4f}\")\n",
    "        if p_corrigido < 0.05:\n",
    "            print(\"Os métodos são estatisticamente diferentes.\")\n",
    "        else:\n",
    "            print(\"Os métodos são estatisticamente equivalentes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15a97f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holdout\n",
    "\n",
    "def holdout(modelo_cls, X, y, rep, test_size=0.2, best_params=None):\n",
    "    print(\"\\n --- Holdout --- \")\n",
    "    acuracias = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(rep):\n",
    "        print(f\"\\nRepetição {i}:\")\n",
    "\n",
    "        # Divide os dados diretamente\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=i)\n",
    "\n",
    "        # Instancia o modelo com os melhores parâmetros (se houver)\n",
    "        modelo = modelo_cls(**best_params) if best_params else modelo_cls()\n",
    "\n",
    "        # Treinamento e predição\n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_pred = modelo.predict(X_test)\n",
    "\n",
    "        # Métricas\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        acuracias.append(acc)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        print(f\"  Acurácia: {acc}\")\n",
    "        print(f\"  F1 Score (macro): {f1}\")\n",
    "\n",
    "    print(\"\\nMÉDIA FINAL HOLDOUT:\")\n",
    "    acuracia_media, acuracia_desvio, acuracia_ic = calcular_intervalo_confianca(acuracias)\n",
    "    f1_media, f1_desvio, f1_ic = calcular_intervalo_confianca(f1_scores)\n",
    "\n",
    "    print(f\"  Acurácia média após Holdout: {acuracia_media:.4f} (± {acuracia_ic:.4f})\")\n",
    "    print(f\"  Desvio padrão da Acurácia: {acuracia_desvio:.4f}\")\n",
    "    print(f\"  F1 Score (macro) médio: {f1_media:.4f} (± {f1_ic:.4f})\")\n",
    "    print(f\"  Desvio padrão do F1 Score (macro): {f1_desvio:.4f}\")\n",
    "\n",
    "    return acuracias, f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f61c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K Fold\n",
    "\n",
    "def stratified_k_fold(modelo, X, y, best_params, k=10):\n",
    "    print(\"\\n --- Stratified K Fold ---\")\n",
    "    skf = StratifiedKFold(n_splits=k)\n",
    "    acuracias = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Fold {i}:\")\n",
    "        \n",
    "        # Dividindo os dados em treino e teste\n",
    "        X_fold_train, X_fold_test = X[train_idx], X[test_idx]\n",
    "        y_fold_train, y_fold_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Inicializando o modelo com os melhores parâmetros\n",
    "        clf_fold = modelo(**best_params) if (best_params) else modelo()\n",
    "        \n",
    "        # Treinando o modelo\n",
    "        clf_fold.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Predição\n",
    "        y_pred_fold = clf_fold.predict(X_fold_test)\n",
    "\n",
    "        # Calculando as métricas\n",
    "        acc = accuracy_score(y_fold_test, y_pred_fold)\n",
    "        f1 = f1_score(y_fold_test, y_pred_fold, average='macro')\n",
    "\n",
    "        # Armazenando os resultados\n",
    "        acuracias.append(acc)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # Exibindo os resultados por fold\n",
    "        print(f\"  Acurácia do Fold {i}: {acc}\")\n",
    "        print(f\"  F1 Score (macro) do Fold {i}: {f1}\")\n",
    "\n",
    "    acuracia_media, acuracia_desvio, acuracia_ic = calcular_intervalo_confianca(acuracias)\n",
    "    f1_media, f1_desvio, f1_ic = calcular_intervalo_confianca(f1_scores)\n",
    "\n",
    "    # Exibindo as métricas médias\n",
    "    print(f\"\\nAcurácia média após K-Fold: {acuracia_media:.4f} (± {acuracia_ic:.4f})\")\n",
    "    print(f\"F1 Score (macro) médio após K-Fold: {f1_media:.4f} (± {f1_ic:.4f})\")\n",
    "    print(f\"  Desvio padrão da Acurácia: {acuracia_desvio:.4f}\")\n",
    "    print(f\"  Desvio padrão do F1 Score (macro): {f1_desvio:.4f}\")\n",
    "\n",
    "    return acuracias, f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8d5e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados do BERT em treino e teste\n",
    "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(X_bert_numpy, y_bert_numpy, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "606eaf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ÁRVORE DE DECISÃO ---\n",
      "Melhores parâmetros:  {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "\n",
      "Acurácia com os melhores parâmetros: 0.9372197309417041\n",
      "F1 Score (macro) com os melhores parâmetros: 0.8552764303620963\n",
      "\n",
      " --- Stratified K Fold ---\n",
      "Fold 0:\n",
      "  Acurácia do Fold 0: 0.9354838709677419\n",
      "  F1 Score (macro) do Fold 0: 0.8564814814814814\n",
      "Fold 1:\n",
      "  Acurácia do Fold 1: 0.9229390681003584\n",
      "  F1 Score (macro) do Fold 1: 0.8295820164068326\n",
      "Fold 2:\n",
      "  Acurácia do Fold 2: 0.9515260323159784\n",
      "  F1 Score (macro) do Fold 2: 0.8942025621003313\n",
      "Fold 3:\n",
      "  Acurácia do Fold 3: 0.9371633752244165\n",
      "  F1 Score (macro) do Fold 3: 0.8612504893064303\n",
      "Fold 4:\n",
      "  Acurácia do Fold 4: 0.940754039497307\n",
      "  F1 Score (macro) do Fold 4: 0.8660208611226521\n",
      "Fold 5:\n",
      "  Acurácia do Fold 5: 0.9389587073608617\n",
      "  F1 Score (macro) do Fold 5: 0.8644186712485682\n",
      "Fold 6:\n",
      "  Acurácia do Fold 6: 0.9443447037701975\n",
      "  F1 Score (macro) do Fold 6: 0.8825637781994519\n",
      "Fold 7:\n",
      "  Acurácia do Fold 7: 0.9443447037701975\n",
      "  F1 Score (macro) do Fold 7: 0.8825637781994519\n",
      "Fold 8:\n",
      "  Acurácia do Fold 8: 0.9210053859964094\n",
      "  F1 Score (macro) do Fold 8: 0.826587795765878\n",
      "Fold 9:\n",
      "  Acurácia do Fold 9: 0.9425493716337523\n",
      "  F1 Score (macro) do Fold 9: 0.8794372294372295\n",
      "\n",
      "Acurácia média após K-Fold: 0.9379 (± 0.0065)\n",
      "F1 Score (macro) médio após K-Fold: 0.8643 (± 0.0152)\n",
      "  Desvio padrão da Acurácia: 0.0090\n",
      "  Desvio padrão do F1 Score (macro): 0.0212\n",
      "\n",
      " --- Holdout --- \n",
      "\n",
      "Repetição 0:\n",
      "  Acurácia: 0.9345291479820628\n",
      "  F1 Score (macro): 0.8513792089747639\n",
      "\n",
      "Repetição 1:\n",
      "  Acurácia: 0.9309417040358744\n",
      "  F1 Score (macro): 0.8545720330441882\n",
      "\n",
      "Repetição 2:\n",
      "  Acurácia: 0.9309417040358744\n",
      "  F1 Score (macro): 0.8432356039870799\n",
      "\n",
      "MÉDIA FINAL HOLDOUT:\n",
      "  Acurácia média após Holdout: 0.9321 (± 0.0042)\n",
      "  Desvio padrão da Acurácia: 0.0017\n",
      "  F1 Score (macro) médio: 0.8497 (± 0.0119)\n",
      "  Desvio padrão do F1 Score (macro): 0.0048\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- ÁRVORE DE DECISÃO ---\")\n",
    "melhores_parametros_arvore = arvore_de_decisao(X_train_bert, y_train_bert, X_test_bert, y_test_bert)\n",
    "resultados_arvore_k_fold = stratified_k_fold(DecisionTreeClassifier, X_bert_numpy, y_bert_numpy, melhores_parametros_arvore, 10)\n",
    "resultados_arvore_holdout = holdout(DecisionTreeClassifier, X_bert_numpy, y_bert_numpy, 3, 0.2, melhores_parametros_arvore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c567a370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- KNN ---\n",
      "Melhores parâmetros:  {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "Acurácia com os melhores parâmetros: 0.9560538116591928\n",
      "F1 Score (macro) com os melhores parâmetros: 0.9053724741023506\n",
      "\n",
      " --- Stratified K Fold ---\n",
      "Fold 0:\n",
      "  Acurácia do Fold 0: 0.9695340501792115\n",
      "  F1 Score (macro) do Fold 0: 0.9376589578281185\n",
      "Fold 1:\n",
      "  Acurácia do Fold 1: 0.9516129032258065\n",
      "  F1 Score (macro) do Fold 1: 0.9030121218753822\n",
      "Fold 2:\n",
      "  Acurácia do Fold 2: 0.9712746858168761\n",
      "  F1 Score (macro) do Fold 2: 0.9390524127366233\n",
      "Fold 3:\n",
      "  Acurácia do Fold 3: 0.9605026929982047\n",
      "  F1 Score (macro) do Fold 3: 0.916197067512857\n",
      "Fold 4:\n",
      "  Acurácia do Fold 4: 0.9640933572710951\n",
      "  F1 Score (macro) do Fold 4: 0.9262486097134686\n",
      "Fold 5:\n",
      "  Acurácia do Fold 5: 0.9533213644524237\n",
      "  F1 Score (macro) do Fold 5: 0.8975291520434734\n",
      "Fold 6:\n",
      "  Acurácia do Fold 6: 0.9748653500897666\n",
      "  F1 Score (macro) do Fold 6: 0.9472537878787879\n",
      "Fold 7:\n",
      "  Acurácia do Fold 7: 0.9461400359066428\n",
      "  F1 Score (macro) do Fold 7: 0.8938157694067409\n",
      "Fold 8:\n",
      "  Acurácia do Fold 8: 0.947935368043088\n",
      "  F1 Score (macro) do Fold 8: 0.8889163967458205\n",
      "Fold 9:\n",
      "  Acurácia do Fold 9: 0.9622980251346499\n",
      "  F1 Score (macro) do Fold 9: 0.9204464303931771\n",
      "\n",
      "Acurácia média após K-Fold: 0.9602 (± 0.0068)\n",
      "F1 Score (macro) médio após K-Fold: 0.9170 (± 0.0140)\n",
      "  Desvio padrão da Acurácia: 0.0096\n",
      "  Desvio padrão do F1 Score (macro): 0.0196\n",
      "\n",
      " --- Holdout --- \n",
      "\n",
      "Repetição 0:\n",
      "  Acurácia: 0.9560538116591928\n",
      "  F1 Score (macro): 0.9053724741023506\n",
      "\n",
      "Repetição 1:\n",
      "  Acurácia: 0.9524663677130045\n",
      "  F1 Score (macro): 0.9091300503594357\n",
      "\n",
      "Repetição 2:\n",
      "  Acurácia: 0.9587443946188341\n",
      "  F1 Score (macro): 0.9124002568727114\n",
      "\n",
      "MÉDIA FINAL HOLDOUT:\n",
      "  Acurácia média após Holdout: 0.9558 (± 0.0064)\n",
      "  Desvio padrão da Acurácia: 0.0026\n",
      "  F1 Score (macro) médio: 0.9090 (± 0.0071)\n",
      "  Desvio padrão do F1 Score (macro): 0.0029\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- KNN ---\")\n",
    "melhores_parametros_knn = knn(X_train_bert, y_train_bert, X_test_bert, y_test_bert)\n",
    "resultados_knn_k_fold = stratified_k_fold(KNeighborsClassifier, X_bert_numpy, y_bert_numpy, melhores_parametros_knn or {}, 10)\n",
    "resultados_knn_holdout = holdout(KNeighborsClassifier, X_bert_numpy, y_bert_numpy, 3, 0.2, melhores_parametros_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdc68ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SVM ---\n",
      "Melhores parâmetros encontrados: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Acurácia: 0.9713004484304932\n",
      "F1-Score Macro: 0.9317029845489487\n",
      "\n",
      " --- Stratified K Fold ---\n",
      "Fold 0:\n",
      "  Acurácia do Fold 0: 0.9731182795698925\n",
      "  F1 Score (macro) do Fold 0: 0.9412396537562393\n",
      "Fold 1:\n",
      "  Acurácia do Fold 1: 0.9802867383512545\n",
      "  F1 Score (macro) do Fold 1: 0.9558858407779272\n",
      "Fold 2:\n",
      "  Acurácia do Fold 2: 0.9820466786355476\n",
      "  F1 Score (macro) do Fold 2: 0.9605881354013359\n",
      "Fold 3:\n",
      "  Acurácia do Fold 3: 0.9640933572710951\n",
      "  F1 Score (macro) do Fold 3: 0.9151690526957051\n",
      "Fold 4:\n",
      "  Acurácia do Fold 4: 0.9784560143626571\n",
      "  F1 Score (macro) do Fold 4: 0.952147766323024\n",
      "Fold 5:\n",
      "  Acurácia do Fold 5: 0.9712746858168761\n",
      "  F1 Score (macro) do Fold 5: 0.933832264195771\n",
      "Fold 6:\n",
      "  Acurácia do Fold 6: 0.9820466786355476\n",
      "  F1 Score (macro) do Fold 6: 0.9605881354013359\n",
      "Fold 7:\n",
      "  Acurácia do Fold 7: 0.9748653500897666\n",
      "  F1 Score (macro) do Fold 7: 0.9448233895618703\n",
      "Fold 8:\n",
      "  Acurácia do Fold 8: 0.9622980251346499\n",
      "  F1 Score (macro) do Fold 8: 0.9126104789725735\n",
      "Fold 9:\n",
      "  Acurácia do Fold 9: 0.9802513464991023\n",
      "  F1 Score (macro) do Fold 9: 0.9563930109248782\n",
      "\n",
      "Acurácia média após K-Fold: 0.9749 (± 0.0049)\n",
      "F1 Score (macro) médio após K-Fold: 0.9433 (± 0.0120)\n",
      "  Desvio padrão da Acurácia: 0.0068\n",
      "  Desvio padrão do F1 Score (macro): 0.0168\n",
      "\n",
      " --- Holdout --- \n",
      "\n",
      "Repetição 0:\n",
      "  Acurácia: 0.9713004484304932\n",
      "  F1 Score (macro): 0.9317029845489487\n",
      "\n",
      "Repetição 1:\n",
      "  Acurácia: 0.9650224215246637\n",
      "  F1 Score (macro): 0.9267422408434118\n",
      "\n",
      "Repetição 2:\n",
      "  Acurácia: 0.9704035874439462\n",
      "  F1 Score (macro): 0.932403013618602\n",
      "\n",
      "MÉDIA FINAL HOLDOUT:\n",
      "  Acurácia média após Holdout: 0.9689 (± 0.0069)\n",
      "  Desvio padrão da Acurácia: 0.0028\n",
      "  F1 Score (macro) médio: 0.9303 (± 0.0063)\n",
      "  Desvio padrão do F1 Score (macro): 0.0025\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- SVM ---\")\n",
    "melhores_parametros_svm = svm_modelo(X_train_bert, y_train_bert, X_test_bert, y_test_bert)\n",
    "resultados_svm_k_fold = stratified_k_fold(SVC, X_bert_numpy, y_bert_numpy, melhores_parametros_svm, 10)\n",
    "resultados_svm_holdout = holdout(SVC, X_bert_numpy, y_bert_numpy, 3, 0.2, melhores_parametros_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2c7f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testes Houldout: \n",
      "Teste T entre Árvore de Decisão e KNN: valor_p = 0.0004\n",
      "Teste T entre Árvore de Decisão e SVM: valor_p = 0.0001\n",
      "Teste T entre KNN e SVM: valor_p = 0.0079\n",
      "P-value corrigido Bonferroni (Árvore de Decisão vs KNN): 0.0012\n",
      "Os métodos são estatisticamente diferentes.\n",
      "P-value corrigido Bonferroni (Árvore de Decisão vs SVM): 0.0003\n",
      "Os métodos são estatisticamente diferentes.\n",
      "P-value corrigido Bonferroni (KNN vs SVM): 0.0238\n",
      "Os métodos são estatisticamente diferentes.\n",
      "Testes K fold: \n",
      "Teste T entre Árvore de Decisão e KNN: valor_p = 0.0001\n",
      "Teste T entre Árvore de Decisão e SVM: valor_p = 0.0000\n",
      "Teste T entre KNN e SVM: valor_p = 0.0014\n",
      "P-value corrigido Bonferroni (Árvore de Decisão vs KNN): 0.0002\n",
      "Os métodos são estatisticamente diferentes.\n",
      "P-value corrigido Bonferroni (Árvore de Decisão vs SVM): 0.0000\n",
      "Os métodos são estatisticamente diferentes.\n",
      "P-value corrigido Bonferroni (KNN vs SVM): 0.0043\n",
      "Os métodos são estatisticamente diferentes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Testes Houldout: \")\n",
    "\n",
    "resultados_comparacao_houldout = {\n",
    "    'Árvore de Decisão': resultados_arvore_holdout[0],\n",
    "    'KNN': resultados_knn_holdout[0],\n",
    "    'SVM': resultados_svm_holdout[0]\n",
    "}\n",
    "\n",
    "comparar_modelos_teste_t(resultados_comparacao_houldout)\n",
    "\n",
    "print(\"Testes K fold: \")\n",
    "\n",
    "resultados_comparacao_k_fold = {\n",
    "    'Árvore de Decisão': resultados_arvore_k_fold[0],\n",
    "    'KNN': resultados_knn_k_fold[0],\n",
    "    'SVM': resultados_svm_k_fold[0]\n",
    "}\n",
    "\n",
    "comparar_modelos_teste_t(resultados_comparacao_k_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b4f0f",
   "metadata": {},
   "source": [
    "## Classificação Zero Shot com BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2098df4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia zero-shot: 0.6782124910265613\n",
      "\n",
      "Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.86      0.75      0.80      4825\n",
      "        spam       0.10      0.19      0.13       747\n",
      "\n",
      "    accuracy                           0.68      5572\n",
      "   macro avg       0.48      0.47      0.47      5572\n",
      "weighted avg       0.76      0.68      0.71      5572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "texts = df_clean['Message_clean'].astype(str).fillna(\"\").tolist()\n",
    "labels_texto = df_clean['Label'].tolist()\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "candidate_labels = [\"ham\", \"spam\"]\n",
    "predictions = []\n",
    "\n",
    "for text in texts:\n",
    "    result = classifier(text, candidate_labels)\n",
    "    predicted_label = result['labels'][0]  \n",
    "    predictions.append(predicted_label)\n",
    "\n",
    "\n",
    "acc = accuracy_score(labels_texto, predictions)\n",
    "print(\"Acurácia zero-shot:\", acc)\n",
    "print(\"\\nRelatório de classificação:\\n\", classification_report(labels_texto, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67866afa",
   "metadata": {},
   "source": [
    "### Passo 9: Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f16fbe",
   "metadata": {},
   "source": [
    "Rodar em alguma máquina do laboratório. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3e153",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Carregando o modelo\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBertModel\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m num_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Definindo um cabeçalho classificador\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BertModel' is not defined"
     ]
    }
   ],
   "source": [
    "# Carregando o modelo\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "num_labels = 2\n",
    "# Definindo um cabeçalho classificador\n",
    "classifier = nn.Linear(768, num_labels)\n",
    "\n",
    "# Concatenando o codificador e o classificador\n",
    "model = nn.Sequential(model, classifier)\n",
    "\n",
    "# Definindo um otimizador e uma função de perda para o modelo.\n",
    "# Usando perda de entropia cruzada para os classificadores\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Criando os objetos DataLoader a partir do conjunto de dados\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5817d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de treinamento\n",
    "def train(model, optimizer, train_loader, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, attention_mask, labels = batch \n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Training loss: {total_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d622d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, labels = batch  \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            total_acc += (predictions == labels).sum().item()\n",
    "\n",
    "    print(f'Test loss: {total_loss/len(test_loader)} Test acc: {total_acc/len(test_set)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    train(model, optimizer, train_loader, criterion)\n",
    "    evaluate(model, test_loader, criterion)\n",
    "\n",
    "# Salvando o modelo\n",
    "torch.save(model.state_dict(), ' sentiment_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Treinamento",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
